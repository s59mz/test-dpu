{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2oFeWXltnxb"
   },
   "source": [
    "## RF Modulation Recognition with Vitis-AI - Part-2\n",
    "\n",
    "This is a modified scrpit, prepaired to run on the Google Colab with a reduced RF Dataset to 6% only.\n",
    "\n",
    "Original project is located on the Xilinx GitHub repository:\n",
    "\n",
    "https://github.com/Xilinx/Vitis-AI-Tutorials/tree/master/Design_Tutorials/10-RF_modulation_recognition\n",
    "\n",
    "\n",
    "The reduced RF Dataset is located on my shared folder on the Google Drive.\n",
    "\n",
    "\n",
    "###Run this script on the Host Computer in the Vitis-AI Docker.\n",
    "\n",
    "\n",
    "At the end copy the compiled 'rfClassification.xmodel' to your FPGA board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YA5KFFeq8_PJ"
   },
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3047,
     "status": "ok",
     "timestamp": 1647973476859,
     "user": {
      "displayName": "Matjaz Zibert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjxo8wQa943D739AYiNxos4RgExuqUIJbw1QcbN=s64",
      "userId": "01767470950860479027"
     },
     "user_tz": -60
    },
    "id": "UQW00mw3ymJX",
    "outputId": "420fc258-1a13-4d6b-d6a7-9c0e49628bc8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 17:07:39.964255: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib:/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib\n",
      "2022-03-22 17:07:39.964283: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version is  2.6.0\n",
      "Keras version      :  2.6.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow import Tensor\n",
    "print(\"Tensorflow version is \", tf.__version__)\n",
    "print('Keras version      : ',keras.__version__)\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import h5py as h5\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import random\n",
    "import time\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Conv2DTranspose, Concatenate, BatchNormalization, UpSampling2D\n",
    "from tensorflow.keras.layers import  Dropout, Activation, GlobalAveragePooling1D, ZeroPadding2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adadelta\n",
    "from tensorflow.keras.layers import Reshape, Dense, Flatten, Add\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, History\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from random import shuffle\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "from progressbar import ProgressBar\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEwdbt6MBcjS"
   },
   "source": [
    "## Download the reduced 2018.01 Dataset \n",
    "It has only 6.25% of original data. The file size is about 1.25 GB. Enough to test the model on DPU of the FPGA.\n",
    "\n",
    "If you need a more accurate model, then use the original dataset. You need at least 20 GB of free disk space just for download.\n",
    "\n",
    "Only 512 samples per SNR, only upper 12 SNRs are included in the reduced dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15068,
     "status": "ok",
     "timestamp": 1647973160126,
     "user": {
      "displayName": "Matjaz Zibert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjxo8wQa943D739AYiNxos4RgExuqUIJbw1QcbN=s64",
      "userId": "01767470950860479027"
     },
     "user_tz": -60
    },
    "id": "kqhq1rQs1Sqo",
    "outputId": "49a06804-c69a-4428-be80-64c83342324a"
   },
   "outputs": [],
   "source": [
    "# FILENAME = reduced_rf_dataset_XYZ.hdf5\n",
    "# FILEID = 1O_pmhLc7t3W4ehsFFUfYOaZsvyEmNVkn\n",
    "\n",
    "# wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=FILEID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=FILEID\" -O FILENAME && rm -rf /tmp/cookies.txt\n",
    "\n",
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1O_pmhLc7t3W4ehsFFUfYOaZsvyEmNVkn' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1O_pmhLc7t3W4ehsFFUfYOaZsvyEmNVkn\" -O reduced_rf_dataset_XYZ.hdf5 && rm -rf /tmp/cookies.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1647975228598,
     "user": {
      "displayName": "Matjaz Zibert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjxo8wQa943D739AYiNxos4RgExuqUIJbw1QcbN=s64",
      "userId": "01767470950860479027"
     },
     "user_tz": -60
    },
    "id": "TFen2ML3xkUc",
    "outputId": "95a42b66-2541-43ab-ed40-563612d337d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1309168\r\n",
      "-rw-rw-r-- 1 vitis-ai-user vitis-ai-group         36 Mar 22 16:58 arch_b1152.json\r\n",
      "drwxrwxr-x 2 vitis-ai-user vitis-ai-group       4096 Mar 22 16:46 fp_model\r\n",
      "-rw-r--r-- 1 vitis-ai-user vitis-ai-group 1340573696 Mar 22 16:44 reduced_rf_dataset_XYZ.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46uELugqymJa"
   },
   "source": [
    "## 2018 Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSNV8sku8_PU"
   },
   "source": [
    "### Read in RF Data\n",
    "3 Arrays will be created. <br>\n",
    "myData holds the 1024 I and Q time values for each input sample. <br>\n",
    "myMods holds the one hot encoded RF class for each sample.<br>\n",
    "mySNRs holds the SNR value for each sample.<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Adeih-_lymJa"
   },
   "outputs": [],
   "source": [
    "#Note this is needed to aviod a tensorFlow memory issue\n",
    "os.environ['TF_FORCE_CPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 782,
     "status": "ok",
     "timestamp": 1647975236225,
     "user": {
      "displayName": "Matjaz Zibert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjxo8wQa943D739AYiNxos4RgExuqUIJbw1QcbN=s64",
      "userId": "01767470950860479027"
     },
     "user_tz": -60
    },
    "id": "VYj5HuQr8_PW",
    "outputId": "7438edf3-9f8c-4a26-d9b3-06b128b0fc59",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159744, 1024, 2)\n",
      "(159744, 24)\n",
      "(159744, 1)\n"
     ]
    }
   ],
   "source": [
    "# original dataset -     4096 frames per 26 SNR per 24 modulations\n",
    "# reduced dataset  - only 512 framer per 13 SNR per 24 modulations\n",
    "\n",
    "# one frame has 1024 x 2 I/Q samples\n",
    "\n",
    "# data_file = '2018.01/GOLD_XYZ_OSC.0001_1024.hdf5'  # original dataset\n",
    "data_file = 'reduced_rf_dataset_XYZ.hdf5'\n",
    "file_handle = h5.File(data_file,'r+')\n",
    "\n",
    "myData = file_handle['X'][:]  # 159744 IQ samples - 512 per 13 SNR x 24 modulations\n",
    "myMods = file_handle['Y'][:]  # modulations = 24, one-hot encoding\n",
    "mySNRs = file_handle['Z'][:]  # SNRs 26 x 4096 per snr\n",
    "\n",
    "file_handle.close()\n",
    "\n",
    "print(np.shape(myData))\n",
    "print(np.shape(myMods))\n",
    "print(np.shape(mySNRs))\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q9SNHLWy8_Pk"
   },
   "source": [
    "### Remove AM-SSB-WC and AM-SSB_SC from the data set\n",
    "If we leave the AM-SSB-WC and AM-SSB-SC modulations in the data set we will see lower accuracy after quantizing the model to INT8. This is becuase we can more accurately quantize the floating point input data if it is over a smaller range with fewer outlyers as in seen in the other modulations \n",
    "\n",
    "In the next step we will remove these two modulations from the data set. If you want to leave these modulations in, you can skip the next step. Leaving these in will cause an additonal 5% accuracy drop after quantizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1310,
     "status": "ok",
     "timestamp": 1647975098300,
     "user": {
      "displayName": "Matjaz Zibert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjxo8wQa943D739AYiNxos4RgExuqUIJbw1QcbN=s64",
      "userId": "01767470950860479027"
     },
     "user_tz": -60
    },
    "id": "xfC-VAt88_Pl",
    "outputId": "4fd48ac9-c2f0-44ca-b151-029d4c25b188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes is  22\n",
      "(146432, 1024, 2)\n",
      "(146432, 1)\n",
      "(146432, 22)\n",
      "Max value of the data set =  4.5126915\n",
      "Min value of the data set =  -4.457516\n",
      "Mean value of the data set =  0.0006922224\n",
      "Standard Deviation of the data set  0.7962071\n"
     ]
    }
   ],
   "source": [
    "#Skip this entire panel if you want to leave AM-SSB-WC and AM-SSB-SC modulations in the data set\n",
    "#myData = np.concatenate((myData[0:1810432], myData[2023424:2555904]),axis=0)\n",
    "#mySNRs = np.concatenate((mySNRs[0:1810432], mySNRs[2023424:2555904]),axis=0)\n",
    "#myMods = np.concatenate((myMods[0:1810432], myMods[2023424:2555904]),axis=0)\n",
    "\n",
    "myData = np.concatenate((myData[0:113152], myData[126464:159744]),axis=0)\n",
    "mySNRs = np.concatenate((mySNRs[0:113152], mySNRs[126464:159744]),axis=0)\n",
    "myMods = np.concatenate((myMods[0:113152], myMods[126464:159744]),axis=0)\n",
    "\n",
    "\n",
    "#re-onehot encode myMods to 22 from 24\n",
    "length = (np.size(myMods, axis=0))\n",
    "temp = np.concatenate((myMods[:,0:17],myMods[:,19:24]), axis=1)\n",
    "myMods = temp\n",
    "\n",
    "mods = [\n",
    "    'OOK',      '4ASK',      '8ASK',      'BPSK',   'QPSK',    '8PSK',\n",
    "    '16PSK',    '32PSK',     '16APSK',    '32APSK', '64APSK',  '128APSK',\n",
    "    '16QAM',    '32QAM',     '64QAM',     '128QAM', '256QAM',  \n",
    "    'AM-DSB-WC', 'AM-DSB-SC', 'FM', 'GMSK','OQPSK']\n",
    "\n",
    "num_classes = np.shape(mods)[0]\n",
    "print(\"The number of classes is \", num_classes)\n",
    "\n",
    "\n",
    "print(np.shape(myData))\n",
    "print(np.shape(mySNRs))\n",
    "print(np.shape(myMods))\n",
    "\n",
    "print (\"Max value of the data set = \", np.max(myData))\n",
    "print (\"Min value of the data set = \", np.min(myData))\n",
    "print (\"Mean value of the data set = \", np.mean(myData))\n",
    "print (\"Standard Deviation of the data set \", np.std(myData) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIgaorRC8_Po"
   },
   "source": [
    "### Reshape RF data to 2D Matrix\n",
    "We will reshape both the I and Q data from a 1024 long vector to 2D 1024x1 matrix to be conpatabile with 2D convolution commands supported by the DPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "anvK6Ik88_Pp"
   },
   "outputs": [],
   "source": [
    "myDataRs = myData.reshape(myData.shape[0], 1024, 1, 2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2RTT88K8_Pq"
   },
   "source": [
    "### Slpit Data into Trainnig and Validation set\n",
    "We will use 80% of the data for the Training set and 20% for the Test set. \n",
    "The random_state input to the the train_test_split function is set to 0, which means the 80/20 split will be done in a repeatable manner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 547,
     "status": "ok",
     "timestamp": 1647975419539,
     "user": {
      "displayName": "Matjaz Zibert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjxo8wQa943D739AYiNxos4RgExuqUIJbw1QcbN=s64",
      "userId": "01767470950860479027"
     },
     "user_tz": -60
    },
    "id": "En0je_7oymJg",
    "outputId": "42e8f9f0-71e0-472d-bd35-130bf794ad9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29287, 1024, 1, 2)\n",
      "(29287, 22)\n",
      "(29287, 1)\n",
      "(117145, 1024, 1, 2)\n",
      "(117145, 22)\n",
      "(117145, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train ,X_test ,Y_train ,Y_test, Z_train, Z_test =train_test_split(myDataRs, myMods, mySNRs, test_size=0.2, random_state=0)\n",
    "print (np.shape(X_test))\n",
    "print (np.shape(Y_test))\n",
    "print (np.shape(Z_test))\n",
    "print (np.shape(X_train))\n",
    "print (np.shape(Y_train))\n",
    "print (np.shape(Z_train))\n",
    "del myData, myMods, mySNRs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ukBJTE-8_QL"
   },
   "source": [
    "## Vitis AI\n",
    "The Vitis-AI tools will be used the Quantize and Compile the model for accleration on the DPU. <br>\n",
    "Vitis-AI 1.3 now natively supports keras in TensorFlow2, and we can directly read in the .h5 model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2g6pEw9s8_QM"
   },
   "source": [
    "## Quantize Model to INT8\n",
    "The Vitis-AI Quantizer uses a  small set of unlabeled samples to analyze the distribution of the activations. We will use 1000 input samples from the test set. <br>\n",
    "\n",
    "The quantized.h5 model that is produced will be used as input to the Vitis-AI Quantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "h8j6hsP_8_QM",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1500\r\n",
      "-rw-r--r-- 1 vitis-ai-user vitis-ai-group 1532920 Mar 22 16:33 rf-model-best.h5\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 17:07:46.225299: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/cv2/../../lib64:/opt/xilinx/xrt/lib:/usr/lib:/usr/lib/x86_64-linux-gnu:/usr/local/lib:/opt/vitis_ai/conda/envs/vitis-ai-tensorflow/lib\n",
      "2022-03-22 17:07:46.225332: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-22 17:07:46.225370: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "/opt/vitis_ai/conda/envs/vitis-ai-tensorflow2/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAI INFO] Update custom_layer_type: []\n",
      "[VAI INFO] Start CrossLayerEqualization...\n",
      "10/10 [==============================] - 5s 584ms/step\n",
      "[VAI INFO] CrossLayerEqualization Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-22 17:07:55.676364: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VAI INFO] Start Quantize Calibration...\n",
      "32/32 [==============================] - 27s 390ms/step\n",
      "[VAI INFO] Quantize Calibration Done.\n",
      "[VAI INFO] Start Post-Quantize Adjustment...\n",
      "[VAI INFO] Post-Quantize Adjustment Done.\n",
      "[VAI INFO] Quantization Finished.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "total 888\n",
      "-rw-r--r-- 1 vitis-ai-user vitis-ai-group 907056 Mar 22 17:08 quantized_model.h5\n"
     ]
    }
   ],
   "source": [
    "# reload the model in case it was closed\n",
    "!ls -l fp_model/\n",
    "model = tf.keras.models.load_model('fp_model/rf-model-best.h5')\n",
    " \n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "quantizer = vitis_quantize.VitisQuantizer(model)\n",
    "quantized_model = quantizer.quantize_model(calib_dataset = X_test[1:1000])\n",
    "\n",
    "# Save the model\n",
    "!mkdir -p quantize_results\n",
    "quantized_model.save('quantize_results/quantized_model.h5')\n",
    "!ls -l quantize_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lf_fc1Ng8_QN"
   },
   "source": [
    "### Load and Compile Model for Evaluation\n",
    "We can now load and recompile the INT8 model and run evaluations to compare with the floating point model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Qn7X5u8_QN"
   },
   "source": [
    "### Evalute  Model INT8 Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "g3B8VnGO8_QO",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "[1.9708930253982544, 0.573940634727478]\n"
     ]
    }
   ],
   "source": [
    "# load quantized model\n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "with vitis_quantize.quantize_scope():\n",
    "  q_model = tf.keras.models.load_model('quantize_results/quantized_model.h5')\n",
    "\n",
    "q_model.compile(loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "score = q_model.evaluate(X_test, Y_test,  verbose=0, batch_size=1024)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGGpBjpD8_QP"
   },
   "source": [
    "The Overall Top-1 score has gone down by about 3% due to quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uswFKSAZ8_QQ"
   },
   "source": [
    "### Classification Report for INT8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "hwmcpj_P8_QQ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         OOK       0.97      1.00      0.98      1331\n",
      "        4ASK       0.34      0.86      0.49      1340\n",
      "        8ASK       0.88      1.00      0.93      1330\n",
      "        BPSK       0.97      1.00      0.99      1328\n",
      "        QPSK       0.99      0.92      0.96      1344\n",
      "        8PSK       0.32      0.80      0.45      1297\n",
      "       16PSK       0.00      0.00      0.00      1299\n",
      "       32PSK       0.23      0.01      0.01      1293\n",
      "      16APSK       0.82      0.91      0.87      1297\n",
      "      32APSK       0.33      0.92      0.49      1289\n",
      "      64APSK       0.02      0.00      0.00      1337\n",
      "     128APSK       0.12      0.21      0.15      1321\n",
      "       16QAM       0.28      0.09      0.14      1401\n",
      "       32QAM       0.57      0.11      0.19      1312\n",
      "       64QAM       0.38      0.14      0.21      1301\n",
      "      128QAM       0.24      0.00      0.01      1365\n",
      "      256QAM       0.17      0.20      0.19      1359\n",
      "   AM-DSB-WC       0.72      0.87      0.79      1320\n",
      "   AM-DSB-SC       0.81      0.65      0.72      1338\n",
      "          FM       1.00      1.00      1.00      1396\n",
      "        GMSK       1.00      0.94      0.97      1321\n",
      "       OQPSK       0.91      0.98      0.94      1368\n",
      "\n",
      "    accuracy                           0.57     29287\n",
      "   macro avg       0.55      0.57      0.52     29287\n",
      "weighted avg       0.55      0.57      0.52     29287\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "Y_pred = q_model.predict(X_test,batch_size=batch_size)\n",
    "y_pred = np.argmax(Y_pred, axis = 1)\n",
    "y_actual = np.argmax(Y_test, axis = 1)\n",
    "classificationreport_int8 = classification_report(y_actual,y_pred, target_names=mods)\n",
    "print(classificationreport_int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGpAaCT28_QR"
   },
   "source": [
    "### Accuracy vs SNR for INT8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VHVLgSuy8_QR",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7% (1 of 13) |#                        | Elapsed Time: 0:00:09 ETA:   0:01:51"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR:  6 accuracy 0.43244485294117646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15% (2 of 13) |###                      | Elapsed Time: 0:00:16 ETA:   0:01:20"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR:  8 accuracy 0.5372242647058824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23% (3 of 13) |#####                    | Elapsed Time: 0:00:23 ETA:   0:01:13"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR:  10 accuracy 0.5721507352941176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30% (4 of 13) |#######                  | Elapsed Time: 0:00:31 ETA:   0:01:06"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR:  12 accuracy 0.5914522058823529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38% (5 of 13) |#########                | Elapsed Time: 0:00:38 ETA:   0:00:58"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR:  14 accuracy 0.5790441176470589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46% (6 of 13) |###########              | Elapsed Time: 0:00:45 ETA:   0:00:51"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR:  16 accuracy 0.5942095588235294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53% (7 of 13) |#############            | Elapsed Time: 0:00:53 ETA:   0:00:43"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR:  18 accuracy 0.5969669117647058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61% (8 of 13) |###############          | Elapsed Time: 0:01:00 ETA:   0:00:36"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR:  20 accuracy 0.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69% (9 of 13) |#################        | Elapsed Time: 0:01:07 ETA:   0:00:29"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR:  22 accuracy 0.59375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76% (10 of 13) |##################      | Elapsed Time: 0:01:15 ETA:   0:00:22"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR:  24 accuracy 0.5854779411764706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84% (11 of 13) |####################    | Elapsed Time: 0:01:22 ETA:   0:00:14"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR:  26 accuracy 0.5863970588235294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92% (12 of 13) |######################  | Elapsed Time: 0:01:30 ETA:   0:00:07"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR:  28 accuracy 0.5942095588235294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (13 of 13) |########################| Elapsed Time: 0:01:37 Time:  0:01:37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR:  30 accuracy 0.6024816176470589\n"
     ]
    }
   ],
   "source": [
    "batchsize = 128\n",
    "progress = ProgressBar()\n",
    "snrlist = np.unique(Z_test)\n",
    "acc_snr_arr = []\n",
    "\n",
    "# interate over SNRs\n",
    "for snr in progress(snrlist):\n",
    "    acc_arr = []\n",
    "    i_SNR = np.where(Z_test==snr)\n",
    "    X_SNR = X_test[i_SNR[0],:,:]\n",
    "    Y_SNR = Y_test[i_SNR[0],:]\n",
    "    X_SNR_len = np.shape(X_SNR)[0]\n",
    "    total_batches = int(X_SNR_len/batchsize)\n",
    "    \n",
    "    for i in (range(0, total_batches)):\n",
    "        x_batch, y_batch = X_SNR[i*batchsize:i*batchsize+batchsize], Y_SNR[i*batchsize:i*batchsize+batchsize]\n",
    "        \n",
    "        # model prediction\n",
    "        pred = q_model.predict(x_batch)\n",
    "        \n",
    "        #Pediction values are 0-24, corresponding to indices representing different modulation types\n",
    "        pred_ind = np.argmax(pred, axis=1)\n",
    "        expected_ind = np.argmax(y_batch, axis=1)\n",
    "        matches  = sum(np.equal(pred_ind, expected_ind))\n",
    "        acc      = matches/batchsize\n",
    "        acc_arr.append(acc)\n",
    "\n",
    "    # Average the per-batch accuracy values\n",
    "    accuracy = np.mean(acc_arr)\n",
    "    acc_snr_arr.append(accuracy)\n",
    "    print(\"SNR: \", snr, \"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TpOrwUdH8_QT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 72x72 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(1,1))\n",
    "plt.show()\n",
    "fig= plt.figure(figsize=(10,8))\n",
    "plt.plot(snrlist, acc_snr_arr, 'bo-', label='accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('SNR')\n",
    "plt.title(\"Accuracy vs, SNR for INT8 Model\")\n",
    "plt.legend()\n",
    "plt.axis([-22, 32, 0, 1.0])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtahR9uO8_QU"
   },
   "source": [
    "The Accuracy vs SNR looks very similar to the floating point model, expect the accuracy is down by about 5% for higher SNRs from the floating point model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OhcMvpqZ8_QZ"
   },
   "source": [
    "## Compile Model for DPU\n",
    "The Vitis-AI compiler reads in the quantized model and generates an xmodel file which the instruction set for the Xilinx Deep Learning Processor (DPU). The arhictecture option (-a) is used to specify a json file which indicates which hw target the DPU is being compiled for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4yb7nLqR8_QZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "* VITIS_AI Compilation - Xilinx Inc.\n",
      "**************************************************\n",
      "[INFO] Namespace(batchsize=1, inputs_shape=None, layout='NHWC', model_files=['quantize_results/quantized_model.h5'], model_type='tensorflow2', named_inputs_shape=None, out_filename='/tmp/rfClassification_org.xmodel', proto=None)\n",
      "[INFO] tensorflow2 model: /workspace/quantize_results/quantized_model.h5\n",
      "[INFO] keras version: 2.6.0\n",
      "[INFO] Tensorflow Keras model type: functional\n",
      "[INFO] parse raw model     :100%|█| 66/66 [00:00<00:00, 14924.74it/s]           \n",
      "[INFO] infer shape (NHWC)  :100%|█| 110/110 [00:00<00:00, 17555.40it/s]         \n",
      "[INFO] perform level-0 opt :100%|█| 2/2 [00:00<00:00, 53.88it/s]                \n",
      "[INFO] perform level-1 opt :100%|█| 2/2 [00:00<00:00, 219.76it/s]               \n",
      "[INFO] infer shape (NHWC)  :100%|█| 112/112 [00:00<00:00, 15769.65it/s]         \n",
      "[INFO] generate xmodel     :100%|█| 112/112 [00:00<00:00, 2301.74it/s]          \n",
      "[INFO] dump xmodel: /tmp/rfClassification_org.xmodel\n",
      "[UNILOG][INFO] Compile mode: dpu\n",
      "[UNILOG][INFO] Debug mode: function\n",
      "[UNILOG][INFO] Target architecture: DPUCZDX8G_ISA0_B1152_0100002062010103\n",
      "[UNILOG][INFO] Graph name: model_1, with op num: 206\n",
      "[UNILOG][INFO] Begin to compile...\n",
      "[UNILOG][INFO] Total device subgraph number 3, DPU subgraph number 1\n",
      "[UNILOG][INFO] Compile done.\n",
      "[UNILOG][INFO] The meta json is saved to \"/workspace/vai_c_output/meta.json\"\n",
      "[UNILOG][INFO] The compiled xmodel is saved to \"/workspace/vai_c_output/rfClassification.xmodel\"\n",
      "[UNILOG][INFO] The compiled xmodel's md5sum is 7b5cb1a8d0d08ccea94ca186221f66b4, and has been saved to \"/workspace/vai_c_output/md5sum.txt\"\n"
     ]
    }
   ],
   "source": [
    "#For AXU2CGB\n",
    "!vai_c_tensorflow2 -m quantize_results/quantized_model.h5 -a arch_b1152.json -o vai_c_output -n rfClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WR59-0J68_Qa"
   },
   "source": [
    "## Generate Graph Visualization with xir tool.\n",
    "You will see a compiler message about the number of  subgraphs:\n",
    "Total device subgraph number 3, DPU subgraph number 1 <br>\n",
    "This means that are 3 subgraphs created, 1 for the input layer, 1 for for everything up the softmax layer (which runs on the DPU), and one for the softmax. <br>\n",
    "\n",
    "The softmax layer can  optionally be acclerated in programmable logic, however in this tutorial we will implement the softmax layer on the CPU.\n",
    "\n",
    "You can use the the xir command generate a .png file to visulize the graph layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dy0DVGhy8_Qa"
   },
   "outputs": [],
   "source": [
    "!xir png /workspace/vai_c_output/rfClassification.xmodel xmodel.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFwMKNkk8_Qa"
   },
   "source": [
    "### Write out  samples  of Test Data to be used later for HW testing\n",
    "The python function we will run in the target board will read in these numpy files containing the RF data, class, and SNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jY8BXB4_8_Qb"
   },
   "outputs": [],
   "source": [
    "np.save('/workspace/rf_input.npy', X_test[0:1000,:,:])\n",
    "np.save('/workspace/rf_classes.npy', Y_test[0:1000])\n",
    "np.save('/workspace/rf_snrs.npy', Z_test[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RHjntCP8_Qb"
   },
   "source": [
    "Now that a dpu xmodel file has been created you are ready to run on target board. You will need to copy the above 3 files, and the xmodel file from the compiler to your target board.\n",
    "\n",
    "You can close this notebook by entering CtrlC at the console, close the docker container by entering CtrlD, and the proceed with the Tutorial readme instructions."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "rf_classification-Vitis-AI.ipynb",
   "provenance": [
    {
     "file_id": "1mp0jK0jC4dFiOQdp2eQY9iyMrLx6FBVf",
     "timestamp": 1647983798826
    },
    {
     "file_id": "1Z8TTch9di4LxLyQN9yDALaguTRILSg6j",
     "timestamp": 1647956613236
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
